/**
 * RL Trading Agent Types
 * Types for the reinforcement learning trading system
 */

import type { Bias, OrderBlock } from '@/types';

// ============================================
// Actions
// ============================================

/** Discrete actions the agent can take (original full environment) */
export type Action = 0 | 1 | 2 | 3;
export const Actions = {
  HOLD: 0 as Action,
  BUY: 1 as Action,
  SELL: 2 as Action,
  CLOSE: 3 as Action,
} as const;

/** Exit actions for hybrid environment (agent only controls exits) */
export type ExitAction = 0 | 1 | 2 | 3;
export const ExitActions = {
  HOLD: 0 as ExitAction,         // Continue holding
  EXIT_MARKET: 1 as ExitAction,  // Exit at current price
  TIGHTEN_STOP: 2 as ExitAction, // Move SL to breakeven
  TAKE_PARTIAL: 3 as ExitAction, // Exit 50%, trail rest
} as const;

export type ExitActionName = 'hold' | 'exit_market' | 'tighten_stop' | 'take_partial';

export function exitActionToName(action: ExitAction): ExitActionName {
  switch (action) {
    case ExitActions.HOLD: return 'hold';
    case ExitActions.EXIT_MARKET: return 'exit_market';
    case ExitActions.TIGHTEN_STOP: return 'tighten_stop';
    case ExitActions.TAKE_PARTIAL: return 'take_partial';
    default: return 'hold';
  }
}

export type ActionName = 'hold' | 'buy' | 'sell' | 'close';

export function actionToName(action: Action): ActionName {
  switch (action) {
    case Actions.HOLD: return 'hold';
    case Actions.BUY: return 'buy';
    case Actions.SELL: return 'sell';
    case Actions.CLOSE: return 'close';
    default: return 'hold';
  }
}

// ============================================
// Position & Portfolio
// ============================================

export type PositionSide = 'long' | 'short' | 'flat';
export type ActivePositionSide = 'long' | 'short';

export interface Position {
  side: ActivePositionSide;
  entryPrice: number;
  entryIndex: number;
  size: number; // Position size in units
  unrealizedPnL: number;
}

/** Extended position state for hybrid environment with entry tracking */
export interface HybridPosition extends Position {
  // Original position fields inherited

  // Entry context
  stopLoss: number;
  takeProfit: number;
  confluenceLevel: ConfluenceLevel;
  entryATR: number; // ATR at entry for normalization

  // Tracking
  peakPnL: number; // For trailing stop
  barsHeld: number;
  partialExitTaken: boolean;
  stopTightened: boolean;
  // Progressive trailing level reached (0=none, 1=BE, 2=1% profit, 3=trailing)
  trailingLevel: 0 | 1 | 2 | 3;
}

// ============================================
// Entry Filter (Hybrid System)
// ============================================

/** Confluence level based on signal count */
export type ConfluenceLevel = 'A+' | 'A' | 'B' | 'C';

/** Entry signal generated by rule-based filter */
export interface EntrySignal {
  direction: 'long' | 'short';
  confluenceLevel: ConfluenceLevel;
  confluenceCount: number;
  triggerPrice: number;
  orderBlock: OrderBlock;
  additionalFactors: string[];
  timestamp: number;
}

/** Configuration for entry filter */
export interface EntryFilterConfig {
  minConfluence: number;           // Minimum confluence factors (default: 3 for A-level)
  requireOBTouch: boolean;         // Must touch OB zone (default: true)
  requireTrendAlignment: boolean;  // Bias must match direction (default: true)
  allowedSessionsUTC: [number, number][]; // Kill zone hours [[start, end], ...]
  maxBarsFromOB: number;           // Max bars since OB formed (default: 50)
  obProximityPercent: number;      // How close price must be to OB (default: 0.002 = 0.2%)
}

export interface Portfolio {
  cash: number;
  equity: number; // cash + unrealizedPnL
  position: Position | null;
  realizedPnL: number;
  totalTrades: number;
  winningTrades: number;
  losingTrades: number;
  maxDrawdown: number;
  peakEquity: number;
}

// ============================================
// State
// ============================================

/** ICT context extracted from detections */
export interface ICTContext {
  bias: Bias;

  // Market structure
  swingHighCount: number;
  swingLowCount: number;
  trendStrength: number; // -1 to 1, negative = bearish
  lastStructureBreakType: 'bos' | 'choch' | 'none';
  barsFromLastBreak: number;

  // BOS/CHoCH specific (new features for RL agent)
  lastBOSDirection: -1 | 0 | 1; // -1 bearish, 0 none, 1 bullish
  lastBOSConfidence: number; // 0-1 quality score
  barsFromLastBOS: number;
  lastCHoCHDirection: -1 | 0 | 1;
  lastCHoCHConfidence: number;
  barsFromLastCHoCH: number;
  structureBreakCount: number; // Total breaks detected
  bosChochRatio: number; // BOS / total (0-1, higher = more trend continuation)

  // Order blocks
  nearestBullishOB: { distance: number; strength: number } | null;
  nearestBearishOB: { distance: number; strength: number } | null;
  priceInBullishOB: boolean;
  priceInBearishOB: boolean;

  // Fair value gaps
  nearestBullishFVG: { distance: number; size: number } | null;
  nearestBearishFVG: { distance: number; size: number } | null;
  priceInBullishFVG: boolean;
  priceInBearishFVG: boolean;

  // Liquidity
  nearestBSL: { distance: number; strength: number } | null; // Buy-side liquidity
  nearestSSL: { distance: number; strength: number } | null; // Sell-side liquidity
  recentSweep: 'bsl' | 'ssl' | 'none';

  // Session
  inKillZone: boolean;
  sessionEncoding: number[]; // One-hot: [asian, london, nyc, london_close]
}

/** Price features extracted from recent candles */
export interface PriceFeatures {
  returns: number[]; // Normalized returns for lookback period
  volatility: number; // Current volatility (normalized)
  atr: number; // Average true range (normalized)
  rsi: number; // RSI normalized to -1 to 1
  macdSignal: number; // MACD signal normalized
  priceFromHigh: number; // Distance from recent high (normalized)
  priceFromLow: number; // Distance from recent low (normalized)
}

/** Position-related features */
export interface PositionFeatures {
  isLong: number; // 1 if long, 0 otherwise
  isShort: number; // 1 if short, 0 otherwise
  unrealizedPnLNorm: number; // Normalized unrealized PnL
  holdingPeriod: number; // Normalized bars in position
}

/** Complete state representation for the agent */
export interface TradingState {
  // Raw features as flat array (for neural network input)
  features: number[];

  // Structured components (for debugging/analysis)
  price: PriceFeatures;
  ict: ICTContext;
  position: PositionFeatures;

  // Context
  currentIndex: number;
  currentPrice: number;
  timestamp: number;
}

/** Simplified state for exit-only agent (18 features) */
export interface ExitState {
  // Raw features for neural network (18 total)
  features: number[];

  // Structured components for debugging
  positionInfo: ExitPositionInfo;
  marketContext: ExitMarketContext;
  priceAction: ExitPriceAction;

  // Context
  currentIndex: number;
  currentPrice: number;
  timestamp: number;
}

/** Position info features (6 features) */
export interface ExitPositionInfo {
  unrealizedPnL: number;        // Normalized by position size
  barsInPosition: number;       // Normalized: min(bars/50, 1)
  distanceToSL: number;         // ATR-normalized
  distanceToTP: number;         // ATR-normalized
  drawdownFromPeak: number;     // (peakPnL - currentPnL) / peakPnL, 0-1
  entryConfluence: number;      // Normalized entry quality score, 0-1
}

/** Market context features (8 features) */
export interface ExitMarketContext {
  priceVsEntry: number;         // % from entry, normalized
  volatilityRatio: number;      // Current ATR / entry ATR
  trendStrength: number;        // 0-1 based on swing structure
  nearestOBDistance: number;    // ATR-normalized
  fvgProximity: number;         // 0 = in FVG, 1 = far
  sessionProgress: number;      // 0-1 within kill zone
  recentBOSConfirmation: number; // BOS confirmed position direction? 0-1
  recentCHoCHWarning: number;   // CHoCH warned against position? 0-1
}

/** Recent price action features (8 features) */
export interface ExitPriceAction {
  returns1bar: number;
  returns3bar: number;
  returns5bar: number;
  returns10bar: number;
  highestSinceEntry: number;    // % above entry
  lowestSinceEntry: number;     // % below entry
  candlePatternScore: number;   // -1 to 1 (bearish to bullish)
  volumeRatio: number;          // Current / average
}

/** Higher timeframe (4H) features for multi-timeframe analysis (3 features) */
export interface HTFFeatures {
  /** Does 4H bias align with position direction? +1 aligned, -1 opposite, 0 neutral */
  htfBiasAlignment: number;
  /** 4H trend strength based on swing structure: -1 bearish to +1 bullish */
  htfTrendStrength: number;
  /** Distance to nearest 4H order block (ATR-normalized, 0-1) */
  htfOBDistance: number;
}

// ============================================
// Environment
// ============================================

export interface StepResult {
  state: TradingState;
  reward: number;
  done: boolean;
  info: StepInfo;
}

/** Step result for hybrid environment */
export interface HybridStepResult {
  state: ExitState | null;  // null when not in position
  reward: number;
  done: boolean;
  info: HybridStepInfo;
}

export interface HybridStepInfo {
  action: ExitAction | null;  // null when not in position
  actionName: ExitActionName | 'waiting';
  price: number;
  portfolio: Portfolio;
  inPosition: boolean;
  entrySignal?: EntrySignal;  // Present if position just opened
  trade?: TradeRecord;
  exitReason?: 'agent' | 'stop_loss' | 'take_profit' | 'max_bars';
}

export interface StepInfo {
  action: Action;
  actionName: ActionName;
  price: number;
  portfolio: Portfolio;
  trade?: TradeRecord;
  rewardComponents: RewardComponents;
}

export interface TradeRecord {
  entryIndex: number;
  exitIndex: number;
  entryPrice: number;
  exitPrice: number;
  side: 'long' | 'short';
  pnl: number;
  pnlPercent: number;
  holdingPeriod: number;
}

// ============================================
// Reward
// ============================================

export interface RewardComponents {
  pnl: number; // Step-wise PnL reward
  sharpe: number; // Risk-adjusted return bonus
  drawdown: number; // Drawdown penalty
  ictAlignment: number; // Bonus for trading with ICT concepts
  total: number; // Weighted sum
}

export interface RewardConfig {
  pnlWeight: number; // Default: 0.4
  sharpeWeight: number; // Default: 0.3
  drawdownWeight: number; // Default: 0.2
  ictAlignmentWeight: number; // Default: 0.1

  // ICT alignment bonuses
  withTrendBonus: number; // Trading with structure
  orderBlockBonus: number; // Entry at OB
  fvgBonus: number; // Entry at FVG
  killZoneBonus: number; // Trading in kill zone
  liquiditySweepBonus: number; // Entry after sweep

  // Penalties
  overTradingPenalty: number; // Too frequent trades
  holdingTooLongPenalty: number; // Positions held too long
}

// ============================================
// Experience Replay
// ============================================

export interface Transition {
  state: number[]; // Flattened state features
  action: Action;
  reward: number;
  nextState: number[]; // Flattened next state features
  done: boolean;
}

export interface ReplayBufferConfig {
  capacity: number; // Default: 100000
  batchSize: number; // Default: 64
  minExperience: number; // Min experiences before training starts
}

// ============================================
// DQN Agent
// ============================================

export interface DQNConfig {
  // Network architecture
  inputSize: number; // Size of state feature vector
  hiddenLayers: number[]; // Default: [256, 128, 64]
  outputSize: number; // 4 (number of actions)

  // Training hyperparameters
  learningRate: number; // Default: 0.0003
  gamma: number; // Discount factor, default: 0.99
  tau: number; // Target network soft update, default: 0.005

  // Exploration
  epsilonStart: number; // Default: 1.0
  epsilonEnd: number; // Default: 0.01
  epsilonDecay: number; // Default: 0.995

  // Regularization
  dropout: number; // Default: 0.2
  l2Regularization: number; // Default: 0.01

  // Training stability
  useBatchNorm?: boolean; // Add batch normalization after each layer
  gradientClipNorm?: number; // Clip gradient norm (default: 1.0)
  useHuberLoss?: boolean; // Use Huber loss instead of MSE
  huberDelta?: number; // Huber loss delta (default: 1.0)

  // Learning rate scheduling
  lrWarmupSteps?: number; // Linear warmup steps (default: 1000)
  lrDecayRate?: number; // Exponential decay rate (default: 0.99)

  // Dueling DQN architecture (optional)
  useDueling?: boolean; // Use Dueling DQN architecture (separate V and A streams)
}

export interface AgentState {
  epsilon: number;
  totalSteps: number;
  episodeCount: number;
  averageReward: number;
  averageLoss: number;
}

// ============================================
// Training
// ============================================

export interface TrainingConfig {
  episodes: number; // Default: 1000
  maxStepsPerEpisode: number; // Default: unlimited (until data ends)

  // Checkpointing
  saveInterval: number; // Save model every N episodes
  evalInterval: number; // Evaluate every N episodes

  // Early stopping
  earlyStoppingPatience: number; // Stop if no improvement for N evals
  minImprovement: number; // Minimum improvement threshold

  // Data
  trainSplit: number; // Default: 0.8 (80% train, 20% validation)

  // Logging
  logInterval: number; // Log every N episodes
  verbose: boolean;

  // Training optimization
  trainFrequency?: number; // Train every N steps, default: 4

  // Walk-forward validation (optional)
  useRollingValidation?: boolean; // Enable rolling window validation
  rollingTrainWindow?: number; // Training window size (default: 500)
  rollingTestWindow?: number; // Test window size (default: 100)
  rollingStepSize?: number; // Step forward size (default: 100)
}

export interface TrainingMetrics {
  episode: number;
  totalReward: number;
  averageReward: number;
  epsilon: number;
  loss: number;

  // Trading metrics
  totalTrades: number;
  winRate: number;
  sharpeRatio: number;
  maxDrawdown: number;
  totalPnL: number;
}

export interface EvaluationResult {
  metrics: TrainingMetrics;
  trades: TradeRecord[];
  equityCurve: number[];
}

// ============================================
// Environment Config
// ============================================

export interface EnvironmentConfig {
  // Trading parameters
  initialCapital: number; // Default: 10000
  positionSize: number; // Fraction of capital per trade, default: 0.1
  maxPositionSize: number; // Max position as fraction of capital

  // Costs (realistic defaults for crypto)
  spread: number; // Bid-ask spread as fraction (0.0001 = 0.01%)
  commission: number; // Per-trade commission as fraction (0.001 = 0.1%)
  slippage: number; // Slippage factor as fraction (0.0005 = 0.05%)

  // State parameters
  lookbackPeriod: number; // Candles to include in state, default: 60

  // Episode parameters
  episodeLength: number | null; // null = use all data
  randomStart: boolean; // Random starting point for diversity

  // Risk management
  maxDrawdownLimit: number; // Stop episode if exceeded
  stopLossPercent?: number; // Per-trade stop loss (default: 2%)
  takeProfitPercent?: number; // Per-trade take profit (default: 4%)
}

// ============================================
// Model Persistence
// ============================================

export interface ModelCheckpoint {
  version: string;
  timestamp: number;
  config: DQNConfig;
  agentState: AgentState;
  trainingMetrics: TrainingMetrics;
  // weights stored separately as JSON-serialized tensors
}

export interface SavedModel {
  checkpoint: ModelCheckpoint;
  weightsPath: string;
}
